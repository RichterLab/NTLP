{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772aafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "# Limit numpy to 1 thread so that\n",
    "# we can parallelize the error analysis\n",
    "# properly\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from droplet_approximation import *\n",
    "\n",
    "# Likewise limit pytroch to 1 thread\n",
    "torch.set_num_threads( 1 )\n",
    "torch.set_num_interop_threads( 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb50436",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do NOT edit this cell. Instead, make any changes you want in the cell below it by setting\n",
    "# these variables.\n",
    "\n",
    "# Commit for each model\n",
    "current_SHA = \"79a3442545133bfe38cecf9b67ab928538842b23\"\n",
    "\n",
    "# Change this to fit wherever testing data is stored. TODO: update this to match particles exploration\n",
    "simulation_name = \"Pi Chamber 1way RH103\"\n",
    "particles_root  = \"/groups/drichte2/droplet_approximation/data/simulations/pi_chamber-1way-rh103/particles\"\n",
    "#particles_root  = \"../data/particles\"\n",
    "dirs_per_level  = 256\n",
    "\n",
    "# This controls how much of the data to load.\n",
    "# The notebook will 1/subset fraction\n",
    "# of the overall dataset.\n",
    "subset_fraction = 1\n",
    "\n",
    "# Good CUSUM parameters for non-iterative, could probably be dialed in more\n",
    "cusum_error_tolerance = np.array( [ 0.005, 0.05 ] )\n",
    "cusum_error_threshold = np.array( [ 0.02, 0.20 ] )\n",
    "\n",
    "norm = standard_norm\n",
    "\n",
    "# How many processes/batches to run the analysis with\n",
    "# Defaults number_processes to multiprocessing.cpu_count() - 1\n",
    "number_processes = 0\n",
    "number_batches = 1\n",
    "\n",
    "\n",
    "# Maximum number of deviation clusters to identify\n",
    "max_clusters = 7\n",
    "\n",
    "# This sets the x-y-z limits for the deviation cluster graph.\n",
    "# Since there are some deviations at very far flung parts of\n",
    "# parameter space, without explicitly setting these ranges,\n",
    "# the deviations are all smooshed together on the graph.\n",
    "set_deviation_graph_limits = False\n",
    "deviation_graph_x_range    = ( -.5,2.0 )\n",
    "deviation_graph_y_range    = ( -6.75, -2.50 )\n",
    "deviation_graph_z_range    = ( 1.0,1.07 )\n",
    "\n",
    "# How many of the worst particles to graph the trajectory of\n",
    "number_graphs = 3\n",
    "\n",
    "# The worst `number_graphs` particles will be picked\n",
    "# only from particles with deviations from all of the listed\n",
    "# clusters. If None, select any particle.\n",
    "# If using strict_graph_cluster_filter, select particles\n",
    "# with ONLY the specified deviations.\n",
    "\n",
    "#deviation_graph_cluster_filter = numpy.array( [0,1,2] )\n",
    "deviation_graph_cluster_filter = None\n",
    "strict_graph_cluster_filter    = False\n",
    "\n",
    "\n",
    "# This array determines where to pickle the analysis reports\n",
    "# to. Does not save if `None`. There must be one path for each\n",
    "# model.\n",
    "save_scores              = True\n",
    "\n",
    "# Determines whether to load scores from pickled files.\n",
    "# If true, deviation analysis WILL NOT BE RUN. Instead,\n",
    "# the notebook will load previous deviation analysis files\n",
    "# from the supplied paths.\n",
    "# There must be one pickled score path for each model.\n",
    "load_scores              = False\n",
    "\n",
    "filter_be_failures = False\n",
    "cold_threshold     = -np.inf\n",
    "\n",
    "reference_evaluation  = {\"be\": \"\"}\n",
    "comparison_evaluation = {\"bdf iterative\": \"bdf_iterative\"}\n",
    "\n",
    "filter_be_failures = False\n",
    "cold_threshold     = -np.inf\n",
    "\n",
    "additional_description = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbfdc1-957d-4ec4-acbc-8c5673a2d8ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edit settings here:\n",
    "reference_tag  = next( iter( reference_evaluation ) )\n",
    "comparison_tag = next( iter( comparison_evaluation ) )\n",
    "\n",
    "#filter_be_failures = True\n",
    "#cold_threshold     = 284.0\n",
    "descriptors = []\n",
    "if filter_be_failures:\n",
    "    descriptors.append( \"BE Failure Filtered\" )\n",
    "if cold_threshold != -np.inf:\n",
    "    descriptors.append( \"Cold_Threshold={:.1f}K\".format( cold_threshold ) )\n",
    "\n",
    "# Note- this affects the save location default!\n",
    "additional_description = \", \".join( descriptors )\n",
    "\n",
    "score_report_dir      = \"/groups/drichte2/droplet_approximation/data/analysis/tmp/\"\n",
    "score_report_suffix   = \"-{:s}\".format( additional_description.lower().replace( \", \", \"-\" ).replace( \" \", \"_\" ) ) if additional_description != \"\" else \"\"\n",
    "score_report_filename = \"scoring_report-{:s}-{:s}_vs_{:s}{:s}.pkl\".format( simulation_name.replace(\" \", \"_\"),\n",
    "                                                                           reference_tag,\n",
    "                                                                           comparison_tag,\n",
    "                                                                           score_report_suffix ).lower().replace(\" \", \"_\")\n",
    "pickled_score_path    = score_report_dir + score_report_filename\n",
    "save_scores           = True\n",
    "load_scores           = False\n",
    "\n",
    "number_batches     = 10\n",
    "\n",
    "#iterative = True\n",
    "# Good CUSUM parameters for iterative, could probably be dialed in more\n",
    "#cusum_error_tolerance = np.array( [ 0.02, 0.10 ] )\n",
    "#cusum_error_threshold = np.array( [ 0.08, 0.40 ] )\n",
    "# You might want more clusters to be identified for iterative as well. This number has not been tuned thoroughly\n",
    "#max_clusters = 12\n",
    "\n",
    "#set_deviation_graph_limits = True\n",
    "#deviation_graph_x_range    = ( -.5,2.0 )\n",
    "#deviation_graph_y_range    = ( -6.75, -2.50 )\n",
    "#deviation_graph_z_range    = ( 1.0,1.07 )\n",
    "\n",
    "# This will select the worst particles deviations from ONLY clusters 1 and 3\n",
    "#strict_graph_cluster_filter    = True\n",
    "#deviation_graph_cluster_filter = np.array( [1, 3] )\n",
    "score_report_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07455e0-77ef-4590-bd96-1af29b19bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_scores and load_scores:\n",
    "    raise( Exception(\"save_scores and load_scores set to True! Set at least one to false to continue.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7547c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20253b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_processes == 0:\n",
    "    number_processes = multiprocessing.cpu_count() - 1\n",
    "number_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8c8ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load or calculate score_reports\n",
    "if load_scores:\n",
    "    try:\n",
    "        with open( pickled_score_path, \"rb\" ) as score_file:\n",
    "            score_report = pickle.load( score_file )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open {load_path}. Encountered error:\\n {e}\")\n",
    "else:\n",
    "    # Extract subset_fraction/256 of the particles and score\n",
    "    ids_index = np.fromfile( particles_root + \"/particles.index\", dtype=np.int32 )\n",
    "    filtered_ids = ids_index[::subset_fraction]\n",
    "\n",
    "    score_report = ScoringReport( particles_root,\n",
    "                                  filtered_ids, \n",
    "                                  dirs_per_level,\n",
    "                                  reference_evaluation,\n",
    "                                  comparison_evaluation,\n",
    "                                  cusum_error_tolerance=cusum_error_tolerance, \n",
    "                                  cusum_error_threshold=cusum_error_threshold,\n",
    "                                  norm=norm,\n",
    "                                  number_processes=number_processes,\n",
    "                                  number_batches=number_batches,\n",
    "                                  filter_be_failures=filter_be_failures,\n",
    "                                  cold_threshold=cold_threshold,\n",
    "                                  max_clusters=12 )\n",
    "\n",
    "    # Dump pickled results\n",
    "    try:\n",
    "        if pickled_score_path is not None:\n",
    "            with open( pickled_score_path, \"wb\" ) as score_file:\n",
    "                pickle.dump( pickled_score_path, score_file )\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save comparison between {:s}/{:s} to file {:s} due to the following exception: \\n {:}\".format( reference_tag,\n",
    "                                                                                                                         comparison_tag,\n",
    "                                                                                                                         pickled_score_path,\n",
    "                                                                                                                         e ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15938b8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We set precision to 2 because otherwise everything is labeled\n",
    "# with very long decimals. We can fix this more thoroughly later\n",
    "# This only matters if label_centers=True\n",
    "with np.printoptions( precision=2 ):\n",
    "    fig,ax = score_report.plot_deviations(label_centers=False, thinning_ratio=10)\n",
    "\n",
    "fig.set_size_inches( ( 8,12 ) )\n",
    "if set_deviation_graph_limits:\n",
    "    ax.set_ylim3d( deviation_graph_x_range ) \n",
    "    ax.set_xlim3d( deviation_graph_y_range ) \n",
    "    ax.set_zlim3d( deviation_graph_z_range ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142a0a4-82b2-4a6f-b4c9-5adfddd90857",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppNRMSE = np.array( list( score_report.per_particle_nrmse.values() ) )\n",
    "print( f\"For comparison {reference_tag}/{comparison_tag}:\\n\"\n",
    "    + f\"Overall NRMSE: {score_report.net_nrmse}\\n\"\n",
    "    + f\"Mean Per Particle NRMSE: {np.mean( ppNRMSE )}\\n\"\n",
    "    + f\"Median Per Particle NRMSE: {np.median( ppNRMSE )}\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c52e1-0c13-4d4a-8b8a-01e1b6c6b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corresponding particle df\n",
    "# Select the worst particles based on NRMSE and filters\n",
    "\n",
    "if deviation_graph_cluster_filter is None:\n",
    "    target_particle_ids = heapq.nlargest( number_graphs, score_report.per_particle_nrmse, \n",
    "                                          key=score_report.per_particle_nrmse.get )\n",
    "else:\n",
    "    # Iterates over each particle's deviations to see if they contain the deviations\n",
    "    # in the cluster filter.\n",
    "    deviation_particle_ids      = score_report.deviation_particle_ids\n",
    "    change_points               = np.array( np.where( deviation_particle_ids[1:] != deviation_particle_ids[:-1] )[0] ) + 1\n",
    "    filtered_per_particle_nrmse = {}\n",
    "    \n",
    "    start_index = 0\n",
    "    for end_index in change_points:\n",
    "        particle_id       = deviation_particle_ids[start_index]\n",
    "        particle_clusters = score_report.deviation_clusters[start_index:end_index]\n",
    "        if np.all( np.isin( deviation_graph_cluster_filter, particle_clusters ) ):\n",
    "            # If strict filtering is on and there are additional deviations\n",
    "            # continue without adding the particle to the list.\n",
    "            if strict_graph_cluster_filter and not np.all( np.isin( particle_clusters, deviation_graph_cluster_filter ) ):\n",
    "                start_index = end_index\n",
    "                continue\n",
    "\n",
    "            filtered_per_particle_nrmse[particle_id] = score_report.per_particle_nrmse[particle_id]\n",
    "\n",
    "        start_index = end_index\n",
    "\n",
    "    target_particle_ids = heapq.nlargest( number_graphs, filtered_per_particle_nrmse, \n",
    "        key=filtered_per_particle_nrmse.get )\n",
    "\n",
    "#ids_index = np.fromfile( particles_root + \"/particles.index\", dtype=np.int32 )\n",
    "#target_particle_ids = np.random.choice( ids_index, 3 )\n",
    "\n",
    "df = read_particles_data( particles_root, target_particle_ids, dirs_per_level, evaluations={\"bdf iterative\": \"bdf_iterative\"}, cold_threshold=cold_threshold )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967e36f-bb01-4c0f-8e13-e8bab28cc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.minorticks_on()\n",
    "plt.grid(color=\"black\", alpha=0.1)\n",
    "plt.xlabel(\"Per Particle NRMSE\")\n",
    "plt.ylabel(\"Particle Count\")\n",
    "plt.title(\"Per Particle NRMSE Histogram for {:s} vs. {:s} {:s}\".format( reference_tag, comparison_tag, additional_description ) )\n",
    "plt.hist( ppNRMSE )\n",
    "plt.yscale( \"log\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each particle, each model will yield 3 figures.\n",
    "# The first will be the figure against BDF\n",
    "# The second will be the figure against BE (with deviations highlighted)\n",
    "# The third will be the figure's CUSUM analysis (calculated within the notebook)\n",
    "\n",
    "# This is the same colormap as in `scoring.py` for plotting deviations\n",
    "colormap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "for particle_id in target_particle_ids:\n",
    "    particle_df      = df.loc[particle_id]\n",
    "    input_parameters = np.stack( particle_df[[\n",
    "        \"input be radii\",\n",
    "        \"input be temperatures\",\n",
    "        \"salt masses\",\n",
    "        \"air temperatures\",\n",
    "        \"relative humidities\",\n",
    "        \"air densities\",\n",
    "        \"integration times\"\n",
    "    ]].to_numpy(), axis=-1 )\n",
    "\n",
    "    reference_output  = np.stack( particle_df[[\"output {:s} radii\".format( \"be\" ),\n",
    "                                               \"output {:s} temperatures\".format( \"be\" )]],\n",
    "                                  axis=-1 )\n",
    "    \n",
    "    comparison_output = np.stack( particle_df[[\"output {:s} radii\".format( \"bdf iterative\" ),\n",
    "                                               \"output {:s} temperatures\".format( \"bdf iterative\" )]],\n",
    "                                  axis=-1 )\n",
    "    times = particle_df[\"times\"]\n",
    "\n",
    "    if filter_be_failures:\n",
    "        be_mask           = particle_df[\"be statuses\"] == 0\n",
    "        input_parameters  = input_parameters[be_mask, :]\n",
    "        reference_output  = reference_output[be_mask, :]\n",
    "        comparison_output = comparison_output[be_mask, :]\n",
    "        times             = times[be_mask]\n",
    "\n",
    "    fig, ax_h = analyze_model_particle_performance( times, reference_output, comparison_output )\n",
    "\n",
    "    fig.suptitle(\"Comparison between {:s}/{:s} with {:s} \\n On particle {:d} from trace {:s}\\n ppNRMSE: {:.4f} \\n SHA: {:s}\".format( reference_tag,\n",
    "                                                                                                                                     comparison_tag,\n",
    "                                                                                                                                     additional_description,\n",
    "                                                                                                                                     particle_id, \n",
    "                                                                                                                                     simulation_name,\n",
    "                                                                                                                                     score_report.per_particle_nrmse[ particle_id ],\n",
    "                                                                                                                                     current_SHA ) )\n",
    "    \n",
    "    # TODO: reintroduce deviation graphing\n",
    "    \"\"\"\n",
    "    be_mask             = be_success_mask( input_parameters[:, 0] )\n",
    "    actual_particle_times = np.delete( np.cumsum( np.insert( input_parameters[:, -1],\n",
    "                                                             0,\n",
    "                                                             0.0 )[:-1] ),\n",
    "                                      ~be_mask ) + particle_df[\"birth time\"]\n",
    "    input_parameters = input_parameters[be_mask]\n",
    "    times            = np.insert( np.cumsum( input_parameters[:, -1] ), 0, 0.0 )[:-1] + particle_df[\"birth time\"]\n",
    "\n",
    "\n",
    "    model_output = np.stack(particle_df[[\"output test_bdf radii\", \"output test_bdf temperatures\"]].to_numpy(), axis=-1)[be_mask]\n",
    "    be_output  = np.stack(particle_df[[\"output be radii\", \"output be temperatures\"]].to_numpy(), axis=-1)[be_mask]\n",
    "\n",
    "    model_outputs = [model_output]\n",
    "    \n",
    "    print(len(model_outputs[0][:-1]))\n",
    "    print(len(be_output))\n",
    "\n",
    "    for model_index in range( model_count ): \n",
    "        fig_h_be, ax_h_be = analyze_model_particle_performance(\n",
    "            times,\n",
    "            input_parameters[:, :2], \n",
    "            model_outputs[model_index],\n",
    "            norm\n",
    "        )\n",
    "\n",
    "        fig_h_be.suptitle( f\"Droplet trajectory overview for particle {particle_id} on model {model_names[model_index]} vs. BE\\n SHA: {commit_SHAs[model_index]}\" ) \n",
    "\n",
    "        fig_h_cusum, ax_h_cusum = plt.subplots( 2, 2, figsize=(9,8) )\n",
    "        fig_h_cusum.suptitle( f\"Droplet trajectory overview part 2 for particle {particle_id} on model { model_names[model_index]}\\n SHA: {commit_SHAs[model_index] }\" ) \n",
    "\n",
    "        #model_cusum = np.abs( calculate_cusum( ( normed_be_output - normed_model_outputs[model_index] ).T, cusum_error_tolerance ) )\n",
    "\n",
    "        #ax_h_cusum[0][0].set_title(\"Radius CUSUM chart\") \n",
    "        #ax_h_cusum[0][0].plot( times, model_cusum[0].T, label=[\"positive radius cusum\", \"negative radius cusum\"] )\n",
    "        #ax_h_cusum[0][0].set_xlabel( \"time (s)\" )\n",
    "        #ax_h_cusum[0][0].axhline( y=cusum_error_threshold[0], color=\"red\",linewidth=1, linestyle=\"--\",label=\"cusum divergence threshold\" )\n",
    "\n",
    "        #ax_h_cusum[0][0].set_ylabel(\"CUSUM\")\n",
    "\n",
    "        #ax_h_cusum[0][1].plot( times, particle_df[\"relative humidities\"][be_mask] )\n",
    "        #ax_h_cusum[0][1].set_title( \"RH versus time for Particle \" + str( model_index ) )\n",
    "        #ax_h_cusum[0][1].set_xlabel( \"time (s)\" )\n",
    "        #ax_h_cusum[0][1].set_ylabel( \"Relative Humidity (%)\" ) \n",
    "\n",
    "\n",
    "        #ax_h_cusum[1][0].plot( times, particle_df[\"air temperatures\"][be_mask] - particle_df[\"input temperatures\"][be_mask] )\n",
    "        #ax_h_cusum[1][0].set_title( f\"Temperature Difference for Particle {particle_id}\" )\n",
    "        #ax_h_cusum[1][0].set_xlabel( \"time (s)\" )\n",
    "        #ax_h_cusum[1][0].set_ylabel( \"Air Temperature (K)\" ) \n",
    "\n",
    "        #ax_h_cusum[1][1].plot( times, particle_df[\"air temperatures\"][be_mask] )\n",
    "        #ax_h_cusum[1][1].set_title( f\"Air Temperatures for Particle {particle_id}\")\n",
    "        #ax_h_cusum[1][1].set_xlabel( \"time (s)\" )\n",
    "        #ax_h_cusum[1][1].set_ylabel( \"time step (s)\" ) \n",
    "\n",
    "        for k, deviation_index in enumerate( np.where( score_reports[model_index].deviation_particle_ids == particle_id )[0] ):\n",
    "            deviation_parameter = score_reports[model_index].deviation_parameters[deviation_index]\n",
    "            deviation_time      = score_reports[model_index].deviation_times[deviation_index]\n",
    "            deviation_cluster   = score_reports[model_index].deviation_clusters[deviation_index]\n",
    "\n",
    "            line_label = f\"{deviation_parameter.name.lower()} deviation, cluster {deviation_cluster}\"\n",
    "\n",
    "            if deviation_parameter == DeviationParameter.RADIUS:\n",
    "                ax_h_be[0][0].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_be[1][0].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                \n",
    "                ax_h_cusum[0][0].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_cusum[0][1].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_cusum[1][0].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_cusum[1][1].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            else:\n",
    "                ax_h_be[0][1].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_be[1][1].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                \n",
    "                ax_h_cusum[0][1].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_cusum[1][0].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                ax_h_cusum[1][1].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "\n",
    "        ax_h_cusum[0][0].legend()\n",
    "        ax_h_cusum[0][1].legend()\n",
    "        ax_h_cusum[1][0].legend()\n",
    "        ax_h_cusum[1][1].legend()\n",
    "\n",
    "        ax_h_be[0][0].legend()\n",
    "        ax_h_be[0][1].legend()\n",
    "        ax_h_be[1][0].legend()\n",
    "        ax_h_be[1][1].legend()\n",
    "        \n",
    "        fig_h_be.tight_layout()\n",
    "        fig_h_cusum.tight_layout()\n",
    "\n",
    "        fig_h_be.show()\n",
    "        fig_h_cusum.show()\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2699800-ce19-4040-b0e7-cb1e4acab11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4987d-39ed-43d1-a3f3-f88d9cf9d866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
