{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757c2b0-de4c-4cce-b0d8-b4fddb09fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import subprocess\n",
    "import os\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "# Limit numpy to 1 thread so that\n",
    "# we can parallelize the error analysis\n",
    "# properly\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import droplet_approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a9d9e-9195-4a62-afc1-f53addd2478c",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f0c5e-899d-461f-aa8c-075d5a2c7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_SHA = str(subprocess.check_output(\"git rev-parse HEAD\", shell=True))[2:-3]\n",
    "\n",
    "# Path to the top-level simulations/ data directory.\n",
    "#\n",
    "# NOTE: This is set to an invalid value as there is no way to set a sensible default.\n",
    "#       The next cell halts execution if it's not set.\n",
    "#\n",
    "simulations_data_root = \"/groups/drichte2/gthomsen/\"\n",
    "\n",
    "# Name of the simulation we're investigating.\n",
    "#\n",
    "# NOTE: This must match one of the names in the next cell!\n",
    "#\n",
    "#simulation_name = \"Pi Chamber - RH~103%, 1-way Coupling\"\n",
    "simulation_name = \"Pi Chamber - 2-way Coupling\"\n",
    "#simulation_name = \"cfog\"\n",
    "#simulation_name = \"Fatima\"\n",
    "#simulation_name = \"Spray\"\n",
    "\n",
    "# Number of processes to use for parallel operations.  Zero means use one process\n",
    "# per core on the system.\n",
    "number_processes = 0\n",
    "\n",
    "# Use a large fanout degree for our raw particle files directory hierarchy.\n",
    "#\n",
    "# NOTE: This must match how the particle directories were constructed.  Do *not* change\n",
    "#       this unless you've updated the common datasets as well.\n",
    "#\n",
    "dirs_per_level   = 256\n",
    "\n",
    "# HISTOGRAM PARAMTERS\n",
    "histogram_count     = 6\n",
    "radbins_count       = 400\n",
    "tempbins_count      = 400\n",
    "averages_count      = 1000\n",
    "background_averages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f466f-3ff8-4ca7-9136-c5b6e63eda62",
   "metadata": {},
   "source": [
    "## Error Analysis Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e54459-7a77-42bd-811c-b79d0fddcb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This controls how much of the data to load.\n",
    "# The notebook will 1/subset fraction\n",
    "# of the overall dataset.\n",
    "subset_fraction = 1\n",
    "\n",
    "# Good CUSUM parameters for non-iterative, could probably be dialed in more\n",
    "cusum_error_tolerance = np.array( [ 0.005, 0.05 ] )\n",
    "cusum_error_threshold = np.array( [ 0.02, 0.20 ] )\n",
    "\n",
    "norm = droplet_approximation.standard_norm\n",
    "\n",
    "# How many processes/batches to run the analysis with\n",
    "# Defaults number_processes to multiprocessing.cpu_count() - 1\n",
    "number_processes = 0\n",
    "number_batches = 1\n",
    "\n",
    "\n",
    "# Maximum number of deviation clusters to identify\n",
    "max_clusters = 7\n",
    "\n",
    "# This sets the x-y-z limits for the deviation cluster graph.\n",
    "# Since there are some deviations at very far flung parts of\n",
    "# parameter space, without explicitly setting these ranges,\n",
    "# the deviations are all smooshed together on the graph.\n",
    "set_deviation_graph_limits = False\n",
    "deviation_graph_x_range    = ( -.5,2.0 )\n",
    "deviation_graph_y_range    = ( -6.75, -2.50 )\n",
    "deviation_graph_z_range    = ( 1.0,1.07 )\n",
    "\n",
    "# How many of the worst particles to graph the trajectory of\n",
    "number_graphs = 3\n",
    "\n",
    "# The worst `number_graphs` particles will be picked\n",
    "# only from particles with deviations from all of the listed\n",
    "# clusters. If None, select any particle.\n",
    "# If using strict_graph_cluster_filter, select particles\n",
    "# with ONLY the specified deviations.\n",
    "\n",
    "#deviation_graph_cluster_filter = numpy.array( [0,1,2] )\n",
    "deviation_graph_cluster_filter = None\n",
    "strict_graph_cluster_filter    = False\n",
    "\n",
    "\n",
    "# This array determines where to pickle the analysis reports\n",
    "# to. Does not save if `None`. There must be one path for each\n",
    "# model.\n",
    "save_scores              = True\n",
    "\n",
    "# Determines whether to load scores from pickled files.\n",
    "# If true, deviation analysis WILL NOT BE RUN. Instead,\n",
    "# the notebook will load previous deviation analysis files\n",
    "# from the supplied paths.\n",
    "# There must be one pickled score path for each model.\n",
    "load_scores              = False\n",
    "\n",
    "filter_be_failures = False\n",
    "cold_threshold     = -np.inf\n",
    "\n",
    "reference_evaluation  = {\"bdf iterative\": \"bdf_iterative\"}\n",
    "comparison_evaluation = {\"mlp gifted finale\": \"mlp_gifted_finale\"}\n",
    "\n",
    "filter_be_failures = False\n",
    "cold_threshold     = -np.inf\n",
    "\n",
    "additional_description = \"\"\n",
    "time_range = [-np.inf, np.inf]\n",
    "\n",
    "number_batches     = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c18b2-c73b-48e8-a620-948ddcda7410",
   "metadata": {},
   "source": [
    "## Change Settings Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edabc4-30f7-4678-ac71-ea199b610c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit settings here:\n",
    "#simulation_name = \"Pi Chamber - RH~103%, 1-way Coupling\"\n",
    "simulation_name = \"Pi Chamber - 2-way Coupling\"\n",
    "#simulation_name = \"cfog\"\n",
    "#simulation_name = \"Fatima\"\n",
    "#simulation_name = \"Spray\"\n",
    "\n",
    "filter_be_failures = False\n",
    "cold_threshold     = -np.inf\n",
    "\n",
    "background_averages = [\"salt masses\", \"air temperatures\", \"relative humidities\", \"air densities\"]\n",
    "\n",
    "save_scores           = True\n",
    "load_scores           = False\n",
    "\n",
    "# Good CUSUM parameters for iterative, could probably be dialed in more\n",
    "#cusum_error_tolerance = np.array( [ 0.02, 0.10 ] )\n",
    "#cusum_error_threshold = np.array( [ 0.08, 0.40 ] )\n",
    "\n",
    "subset_fraction       = 1\n",
    "\n",
    "#set_deviation_graph_limits = True\n",
    "#deviation_graph_x_range    = ( -.5,2.0 )\n",
    "#deviation_graph_y_range    = ( -6.75, -2.50 )\n",
    "#deviation_graph_z_range    = ( 1.0,1.07 )\n",
    "\n",
    "# deviation_graph_cluster_filter = np.array( [1] )\n",
    "# If True, this will select the worst particle with EXACTLY the deviations in the filter\n",
    "# strict_graph_cluster_filter    = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d710c3",
   "metadata": {},
   "source": [
    "# Output Structure\n",
    "The following cell uses the user settings to auto generate an output folder. It also creates a table listing where to store all of the graphs for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48338883-80ec-412c-bc43-51728ac1ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_tag  = next( iter( reference_evaluation ) )\n",
    "comparison_tag = next( iter( comparison_evaluation ) )\n",
    "\n",
    "evaluations = comparison_evaluation | reference_evaluation\n",
    "\n",
    "descriptors = []\n",
    "if filter_be_failures:\n",
    "    descriptors.append( \"BE Failure Filtered\" )\n",
    "if cold_threshold != -np.inf:\n",
    "    descriptors.append( \"Cold_Threshold_{:.1f}K\".format( cold_threshold ) )\n",
    "\n",
    "# Note- this affects the save location default!\n",
    "additional_description = \", \".join( descriptors )\n",
    "\n",
    "analysis_root_dir = \"/groups/drichte2/droplet_approximation/data/analysis/\"\n",
    "analysis_suffix   = \"-{:s}\".format( additional_description.lower().replace( \", \", \"-\" ).replace( \" \", \"_\" ) ) if additional_description != \"\" else \"\"\n",
    "analysis_dir_name = \"error_analysis-{:s}-{:s}_vs_{:s}{:s}/\".format( simulation_name.replace(\",\", \"\")\n",
    "                                                                                   .replace(\"~\",\"_\")\n",
    "                                                                                   .replace(\"%\",\"\")\n",
    "                                                                                   .replace(\" - \", \"_\")\n",
    "                                                                                   .replace(\"-\", \"_\")\n",
    "                                                                                   .replace(\" \", \"_\"),\n",
    "                                                                    reference_tag,\n",
    "                                                                    comparison_tag,\n",
    "                                                                    analysis_suffix ).lower().replace(\" \", \"_\")\n",
    "\n",
    "analysis_dir_path          = analysis_root_dir + analysis_dir_name\n",
    "figures_dir_path           = analysis_dir_path + \"figures/\"\n",
    "deviation_figures_dir_path = figures_dir_path  + \"deviations/\"\n",
    "score_report_path          = analysis_dir_path + \"score_report.pkl\"\n",
    "substitutions_dir_path     = analysis_dir_path + \"substitutions/\"\n",
    "\n",
    "os.makedirs(figures_dir_path, exist_ok=True)\n",
    "os.makedirs(substitutions_dir_path, exist_ok=True)\n",
    "os.makedirs(deviation_figures_dir_path, exist_ok=True)\n",
    "\n",
    "figure_filenames = {\n",
    "    \"RT AVERAGES\": \"radius_temperature_averages.png\",\n",
    "    \"RT AVERAGES SHORT\": \"radius_temperature_averages_short.png\",\n",
    "    \"RADIUS HISTOGRAM\": \"radius_histogram.png\",\n",
    "    \"TEMPERATURE HISTOGRAM\": \"temperature_histogram.png\",\n",
    "    \"RADIUS MULTI HISTOGRAM\": \"radius_multi_histogram.png\",\n",
    "    \"TEMPERATURE MULTI HISTOGRAM\": \"temperature_multi_histogram.png\",\n",
    "    \"DEVIATION CLUSTERS\": \"deviation_clusters.png\",\n",
    "    \"PPNRMSE HISTOGRAM\": \"per_particle_nrmse_histogram.png\",\n",
    "    \"BEST TRAJECTORY\": \"best_trajectory-pid=PARTICLE_ID.png\",\n",
    "    \"RANDOM TRAJECTORY\": \"random_trajectory-pid=PARTICLE_ID.png\",\n",
    "    \"WORST TRAJECTORY\": \"worst_trajectory-pid=PARTICLE_ID.png\"\n",
    "}\n",
    "\n",
    "score_report_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d004c2-333a-404e-9ba5-b792c534374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we know where our data resides, otherwise stop execution.\n",
    "if simulations_data_root is None:\n",
    "    raise ValueError( \"Must set simulations_data_root to run this notebook!\" )\n",
    "\n",
    "# Do we need to default the number of processes to use?\n",
    "if number_processes == 0:\n",
    "    number_processes = os.cpu_count()\n",
    "    \n",
    "# Map the simulation name to its directory beneath the simulations data root.\n",
    "if simulation_name == \"Pi Chamber - RH~103%, 1-way Coupling\":\n",
    "    simulation_directory_name = \"pi_chamber-1way_rh103\"\n",
    "elif simulation_name == \"Pi Chamber - 2-way Coupling\":\n",
    "    simulation_directory_name = \"pi_chamber-2way\"\n",
    "elif simulation_name == \"cfog\":\n",
    "    simulation_directory_name = \"cfog\"\n",
    "elif simulation_name == \"Fatima\":\n",
    "    simulation_directory_name = \"fatima\"\n",
    "elif simulation_name == \"Spray\":\n",
    "    simulation_directory_name = \"spray\"\n",
    "else:\n",
    "    raise ValueError( \"Unknown simulation_name!\" )\n",
    "\n",
    "# Top-level directory of this simulation.\n",
    "simulation_root = \"{:s}/{:s}\".format( simulations_data_root, simulation_directory_name )\n",
    "\n",
    "# Path to the top of the raw particle files directory hierarchy and its index.\n",
    "particles_root       = \"{:s}/particles\".format( simulation_root )\n",
    "particles_index_path = \"{:s}/particles.index\".format( particles_root )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39980f87-4433-417b-8da1-9ab0c19db74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_particle_ids = np.fromfile( particles_index_path, dtype=np.int32 )[::subset_fraction]\n",
    "\n",
    "parallel_read_flag = True\n",
    "if parallel_read_flag:\n",
    "    particles_df = droplet_approximation.batch_read_particles_data( particles_root,\n",
    "                                                                    unique_particle_ids,\n",
    "                                                                    dirs_per_level,\n",
    "                                                                    cold_threshold=cold_threshold,\n",
    "                                                                    filter_be_failures=filter_be_failures,\n",
    "                                                                    evaluations=evaluations,\n",
    "                                                                    number_processes=number_processes )\n",
    "else:\n",
    "    particles_df = droplet_approximation.read_particles_data( particles_root,\n",
    "                                                              unique_particle_ids,\n",
    "                                                              dirs_per_level,\n",
    "                                                              cold_threshold=cold_threshold,\n",
    "                                                              filter_be_failures=filter_be_failures,\n",
    "                                                              evaluations=evaluations)\n",
    "print( \"{:d} particles in the DataFrame.\".format( \n",
    "    len( particles_df ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a9d7b-dd1f-4f2c-b87c-358c583deddc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "radbins  = np.logspace( -8.0, -3.0, radbins_count )\n",
    "tempbins = np.linspace( 273.0, 310.0, tempbins_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d48438-b808-4b8a-b64e-7af141c7c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_times = droplet_approximation.get_particles_data_simulation_times( particles_df )\n",
    "\n",
    "histogram_times  = np.linspace( simulation_times[0], simulation_times[-1], histogram_count )\n",
    "histogram_times  = simulation_times[[np.searchsorted( simulation_times, histogram_times )]][0]\n",
    "\n",
    "averages_indexes = np.linspace( simulation_times[0], simulation_times[-1], averages_count )\n",
    "averages_indexes = np.searchsorted( simulation_times, averages_indexes )\n",
    "averages_times   = simulation_times[[averages_indexes]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf8f85-4898-4980-b803-16ea74a40aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms                       = droplet_approximation.bin_particles_data( particles_df, [reference_tag, comparison_tag], histogram_times, radbins, tempbins )\n",
    "rt_averages, background_averages = droplet_approximation.average_particles_data( particles_df, [reference_tag, comparison_tag], averages_times, background_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c071247-afc4-405e-86d1-4c1355003a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_h = droplet_approximation.plot_droplet_size_temperatures( averages_times, rt_averages, background_parameters=background_averages )\n",
    "\n",
    "fig.suptitle(\"Average Droplet Radii/Temperature for {:s} vs. {:s} in {:s}\".format( reference_tag, comparison_tag, simulation_name ) )\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "ax_h[0][0].set_title(\"Average Radius (m)\")\n",
    "ax_h[0][1].set_title(\"Average Temperature (K)\")\n",
    "\n",
    "ax_h[2][0].set_title(\"Average Salt Mass (kg)\")\n",
    "ax_h[2][1].set_title(\"Average Air Temperature (K)\")\n",
    "ax_h[3][0].set_title(\"Average Relative Humidity (%)\")\n",
    "ax_h[3][1].set_title(\"Average Air Density (g/cm^3)\")\n",
    "\n",
    "ax_h[2][0].set_ylabel(\"Average Salt Mass (kg)\")\n",
    "ax_h[2][1].set_ylabel(\"Average Air Temperature (K)\")\n",
    "ax_h[3][0].set_ylabel(\"Average Relative Humidity (%)\")\n",
    "ax_h[3][1].set_ylabel(\"Average Air Density (g/cm^3)\")\n",
    "\n",
    "plt.savefig(figures_dir_path + figure_filenames[\"RT AVERAGES\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8490ad-9a27-4088-88c1-5992124ed688",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_h = droplet_approximation.plot_droplet_size_temperatures( averages_times, rt_averages )\n",
    "\n",
    "fig.suptitle(\"Average Droplet Radii/Temperature for {:s} vs. {:s} in {:s}\".format( reference_tag, comparison_tag, simulation_name ) )\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "ax_h[0][0].set_title(\"Average Radius (m)\")\n",
    "ax_h[0][1].set_title(\"Average Temperature (K)\")\n",
    "\n",
    "plt.savefig(figures_dir_path + figure_filenames[\"RT AVERAGES SHORT\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6dde0-b5bc-4aad-aaef-30a536652154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogram_count = len(histogram_times)\n",
    "\n",
    "fig, axs = plt.subplots(np.ceil(histogram_count/2.0).astype(int), 2, constrained_layout=True)\n",
    "fig.suptitle(\"Radius Histograms of BE vs. BDF for {:s}\".format( simulation_name ) )\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "for i,time in enumerate(histogram_times):\n",
    "    print(\"Histogram: \", time)\n",
    "    index = [i//2, i%2]\n",
    "\n",
    "    bins = radbins\n",
    "    counts = histograms[reference_tag][0][i, :]\n",
    "    axs[*index].hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=reference_tag)\n",
    "    counts = histograms[comparison_tag][0][i, :]\n",
    "    axs[*index].hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=comparison_tag)\n",
    "    axs[*index].legend()\n",
    "    #axs[*index].axvspan(-4.2757, 0, facecolor='lightgray', alpha=0.8)\n",
    "    axs[*index].set_title(f\"Radius Histogram at Time {time:.2f}s\")\n",
    "    axs[*index].set(xlabel=\"Log Radius (m)\", ylabel=\"# of Particles\", xlim=(1.0e-8, 1.0e-3) )\n",
    "    axs[*index].set_xscale( \"log\" )\n",
    "    axs[*index].grid( alpha=0.1, color=\"black\" )\n",
    "    axs[*index].minorticks_on()\n",
    "\n",
    "\n",
    "plt.savefig(figures_dir_path + figure_filenames[\"RADIUS MULTI HISTOGRAM\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4589f3f-6790-4b32-ab0e-dc13d752b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_count = len(histogram_times)\n",
    "\n",
    "fig, axs = plt.subplots(np.ceil(histogram_count/2.0).astype(int), 2, constrained_layout=True)\n",
    "fig.suptitle(\"Temperature Histograms of BE vs. BDF for {:s}\".format( simulation_name ) \n",
    "            )\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "for i,time in enumerate(histogram_times):\n",
    "    print(\"Histogram: \", time)\n",
    "    index = [i//2, i%2]\n",
    "\n",
    "    bins = tempbins\n",
    "    counts = histograms[reference_tag][1][i, :]\n",
    "    axs[*index].hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=reference_tag)\n",
    "    counts = histograms[comparison_tag][1][i, :]\n",
    "    axs[*index].hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=comparison_tag)\n",
    "    axs[*index].legend()\n",
    "    axs[*index].set_title(f\"Temperature Histogram at Time {time:.2f}s\")\n",
    "    axs[*index].set(xlabel=\"Particle Temperature (K)\", ylabel=\"# of Particles\", xlim=(273, 310) )\n",
    "    axs[*index].grid( alpha=0.1, color=\"black\" )\n",
    "    axs[*index].minorticks_on()\n",
    "\n",
    "plt.savefig(figures_dir_path + figure_filenames[\"TEMPERATURE MULTI HISTOGRAM\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9051b0-f8fb-4025-8d60-b3c04db0e5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogram_sample = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Radius Histogram of BE vs. BDF for {:s} at time {:.2f}s\".format( simulation_name, histogram_times[histogram_sample] ) )\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "bins = radbins\n",
    "counts = histograms[reference_tag][0][histogram_sample, :]\n",
    "plt.hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=reference_tag)\n",
    "counts = histograms[comparison_tag][0][histogram_sample, :]\n",
    "plt.hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=comparison_tag)\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Radius (m)\")\n",
    "plt.ylabel(\"# of Particles\")\n",
    "plt.xlim( (1.0e-8, 1.0e-3) )\n",
    "plt.xscale( \"log\" )\n",
    "plt.grid(alpha=0.1, color=\"black\")\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.savefig(figures_dir_path + figure_filenames[\"RADIUS HISTOGRAM\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8e8f7-91b4-420d-b3b3-f2c89e5b424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_sample = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Temperature Histogram of BE vs. BDF for {:s} at time {:.2f}s\".format( simulation_name, histogram_times[histogram_sample] ) )\n",
    "\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "bins = tempbins\n",
    "counts = histograms[reference_tag][1][histogram_sample, :]\n",
    "plt.hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=reference_tag)\n",
    "counts = histograms[comparison_tag][1][histogram_sample, :]\n",
    "plt.hist(bins[:len(counts)],bins=bins, weights=counts, alpha=0.5, label=comparison_tag)\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"# of Particles\")\n",
    "plt.xlim( (273, 310) )\n",
    "plt.grid(alpha=0.1, color=\"black\")\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.savefig(figures_dir_path + figure_filenames[\"TEMPERATURE HISTOGRAM\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe987aa-b832-4cf5-815d-f3a2e3466444",
   "metadata": {},
   "outputs": [],
   "source": [
    "del particles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810b782",
   "metadata": {},
   "source": [
    "# Error Statistics Calcuations/Plotting\n",
    "Now that averages and histograms have been generated, we unload our particles dataframe to free up memory and the error analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926e3d3-f69f-47d8-8265-2a1ef17943a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load or calculate score_reports\n",
    "if load_scores:\n",
    "    try:\n",
    "        with open( score_report_path, \"rb\" ) as score_file:\n",
    "            score_report = pickle.load( score_file )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open {score_report_path}. Encountered error:\\n {e}\")\n",
    "else:\n",
    "    # Extract subset_fraction/256 of the particles and score\n",
    "    ids_index = np.fromfile( particles_root + \"/particles.index\", dtype=np.int32 )\n",
    "    filtered_ids = ids_index[::subset_fraction]\n",
    "\n",
    "    score_report = droplet_approximation.ScoringReport( particles_root,\n",
    "                                  filtered_ids, \n",
    "                                  dirs_per_level,\n",
    "                                  reference_evaluation,\n",
    "                                  comparison_evaluation,\n",
    "                                  cusum_error_tolerance=cusum_error_tolerance, \n",
    "                                  cusum_error_threshold=cusum_error_threshold,\n",
    "                                  norm=norm,\n",
    "                                  number_processes=number_processes,\n",
    "                                  number_batches=number_batches,\n",
    "                                  filter_be_failures=filter_be_failures,\n",
    "                                  cold_threshold=cold_threshold,\n",
    "                                  max_clusters=12 )\n",
    "\n",
    "    # Dump pickled results\n",
    "    try:\n",
    "        if save_scores is not None:\n",
    "            with open( score_report_path, \"wb\" ) as score_file:\n",
    "                pickle.dump( score_report, score_file )\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save comparison between {:s}/{:s} to file {:s} due to the following exception: \\n {:}\".format( reference_tag,\n",
    "                                                                                                                         comparison_tag,\n",
    "                                                                                                                         pickled_score_path,\n",
    "                                                                                                                         e ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe52c5-645e-47d7-a03f-b899d774aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set precision to 2 because otherwise everything is labeled\n",
    "# with very long decimals. We can fix this more thoroughly later\n",
    "# This only matters if label_centers=True\n",
    "with np.printoptions( precision=2 ):\n",
    "    fig,ax = score_report.plot_deviations(label_centers=False, thinning_ratio=1)\n",
    "\n",
    "fig.set_size_inches( ( 10,10 ) )\n",
    "if set_deviation_graph_limits:\n",
    "    ax.set_ylim3d( deviation_graph_x_range ) \n",
    "    ax.set_xlim3d( deviation_graph_y_range ) \n",
    "    ax.set_zlim3d( deviation_graph_z_range ) \n",
    "\n",
    "plt.savefig( figures_dir_path + figure_filenames[\"DEVIATION CLUSTERS\"], bbox_inches=\"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0f7e2-15af-457a-9640-df066b303176",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ppNRMSE = np.array( list( score_report.per_particle_nrmse.values() ) )\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "plt.minorticks_on()\n",
    "plt.grid(color=\"black\", alpha=0.1)\n",
    "plt.xlabel(\"Per Particle NRMSE\")\n",
    "plt.ylabel(\"Particle Count\")\n",
    "plt.title(\"Per Partficle NRMSE Histogram for {:s} {:s} vs. {:s} - {:s}\".format( simulation_name, reference_tag, comparison_tag, additional_description ) )\n",
    "plt.hist( ppNRMSE, bins=100 )\n",
    "plt.yscale( \"log\" )\n",
    "\n",
    "plt.savefig( figures_dir_path + figure_filenames[\"PPNRMSE HISTOGRAM\"], bbox_inches=\"tight\" )\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae449f-d0c4-4d31-beee-0a3a66683c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph the best, random, and worst graphs\n",
    "deviation_particle_ids = score_report.deviation_particle_ids\n",
    "target_particle_ids = [heapq.nsmallest( 1, score_report.per_particle_nrmse, \n",
    "                                        key=score_report.per_particle_nrmse.get )[0],\n",
    "                       np.random.choice( ids_index, 1)[0],\n",
    "                       heapq.nlargest( 1, score_report.per_particle_nrmse, \n",
    "                                        key=score_report.per_particle_nrmse.get )[0]]\n",
    "figure_identifiers = [\"BEST TRAJECTORY\", \"RANDOM TRAJECTORY\", \"WORST TRAJECTORY\"]\n",
    "\n",
    "particles_df = droplet_approximation.read_particles_data( particles_root,\n",
    "                                                                    target_particle_ids,\n",
    "                                                                    dirs_per_level,\n",
    "                                                                    cold_threshold=cold_threshold,\n",
    "                                                                    filter_be_failures=filter_be_failures,\n",
    "                                                                    evaluations=evaluations )\n",
    "for i in range(3):\n",
    "    particle_df = particles_df.loc[target_particle_ids[i]]\n",
    "    background_parameters = {\n",
    "        \"Salt Mass (kg)\": particle_df[\"salt masses\"],\n",
    "        \"Air Temperature (K)\": particle_df[\"air temperatures\"],\n",
    "        \"Relative Humidity (%)\": particle_df[\"relative humidities\"],\n",
    "        \"Air Density (g/cm^3)\": particle_df[\"air densities\"]\n",
    "    }\n",
    "    fig, ax_h = droplet_approximation.plot_droplet_size_temperatures_scoring( particle_df, score_report, background_parameters=background_parameters)\n",
    "    #fig, ax_h = droplet_approximation.plot_droplet_size_temperatures_dataframe( particle_df, [reference_tag, comparison_tag], background_parameters=background_parameters)\n",
    "    fig.set_figwidth( 14 )\n",
    "    fig.set_figheight( 12 )\n",
    "    figure_filenames[figure_identifiers[i]] = figure_filenames[figure_identifiers[i]].replace( \"PARTICLE_ID\", \"{:d}\".format( particle_df.name ) )\n",
    "    plt.savefig( figures_dir_path + figure_filenames[figure_identifiers[i]], bbox_inches=\"tight\" )\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cluster_count = np.max( score_report.deviation_clusters ) + 1\n",
    "\n",
    "cluster_particle_ids        = [ [] for _ in range( cluster_count ) ]\n",
    "cluster_ppNRMSEs            = [ [] for _ in range( cluster_count ) ]\n",
    "\n",
    "# Collect the ids and NRMSE for the particles in each deviation cluster\n",
    "deviation_particle_ids      = score_report.deviation_particle_ids\n",
    "change_points               = np.array( np.where( deviation_particle_ids[1:] != deviation_particle_ids[:-1] )[0] ) + 1\n",
    "    \n",
    "start_index = 0\n",
    "count = 0\n",
    "for end_index in change_points:\n",
    "    particle_id       = deviation_particle_ids[start_index]\n",
    "    particle_clusters = np.unique( score_report.deviation_clusters[start_index:end_index] )\n",
    "\n",
    "    if count % 100000 == 0:\n",
    "        print(f\"At {count} out of {len( change_points )}\")\n",
    "    for cluster_index in particle_clusters:\n",
    "        cluster_particle_ids[cluster_index].append( particle_id )\n",
    "        cluster_ppNRMSEs[cluster_index].append( score_report.per_particle_nrmse[particle_id] )\n",
    "\n",
    "    start_index = end_index\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036b801-5aab-4c56-94bb-cc8db95b3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_image_substitution_table = pd.DataFrame( columns=[\"CLUSTER PPNRMSE HISTOGRAM\",\n",
    "                                                          \"CLUSTER TRAJECTORY 1\",\n",
    "                                                          \"CLUSTER TRAJECTORY 2\",\n",
    "                                                          \"CLUSTER TRAJECTORY 3\"] )\n",
    "cluster_text_substitution_table  = pd.DataFrame( columns=[\"CLUSTER NAME\",\n",
    "                                                          \"CLUSTER COUNT\",\n",
    "                                                          \"CLUSTER CENTER\",\n",
    "                                                          \"CLUSTER MEAN PPNRMSE\",\n",
    "                                                          \"CLUSTER MEDIAN PPNRMSE\"])\n",
    "image_substitution_rows = []\n",
    "text_substitution_rows  = []\n",
    "\n",
    "# Graph/Tabulate the results for each cluster\n",
    "for cluster_index in range( cluster_count ):\n",
    "    image_substitution_row = {}\n",
    "    text_substitution_row  =  {}\n",
    "    \n",
    "    ppNRMSE = np.array( cluster_ppNRMSEs[cluster_index] )\n",
    "\n",
    "    text_substitution_row[\"CLUSTER NAME\"] = \"Cluster {:d}\".format( cluster_index )\n",
    "    text_substitution_row[\"CLUSTER COUNT\"] = ppNRMSE.shape[0]\n",
    "    text_substitution_row[\"CLUSTER CENTER\"] = [\"{:.2e}\".format( cluster_center ) for cluster_center in score_report.cluster_centers[cluster_index]]\n",
    "    text_substitution_row[\"CLUSTER MEAN PPNRMSE\"] = \"{:.3e}\".format( np.mean( ppNRMSE ) )\n",
    "    text_substitution_row[\"CLUSTER MEDIAN PPNRMSE\"] = \"{:.3e}\".format( np.median( ppNRMSE ) )\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(10)\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(color=\"black\", alpha=0.1)\n",
    "    plt.xlabel(\"Per Particle NRMSE\")\n",
    "    plt.ylabel(\"Particle Count\")\n",
    "    plt.title(\"Per Partficle NRMSE Histogram for Spray {:s} vs. {:s} - {:s}\".format( reference_tag, comparison_tag, additional_description ) )\n",
    "    plt.hist( ppNRMSE, bins=int(np.ceil( np.sqrt( ppNRMSE.shape[0] ) ) ) )\n",
    "    plt.yscale( \"log\" )\n",
    "\n",
    "    histogram_file_name = \"{:s}cluster_{:d}_ppNRMSE_histogram.png\".format( deviation_figures_dir_path, cluster_index )\n",
    "    plt.savefig( histogram_file_name, bbox_inches=\"tight\" )\n",
    "    image_substitution_row[\"CLUSTER PPNRMSE HISTOGRAM\"] = \"cluster_{:d}_ppNRMSE_histogram.png\".format( cluster_index )\n",
    "    plt.close()\n",
    "\n",
    "    target_particle_ids = np.random.choice( cluster_particle_ids[cluster_index], 3 )\n",
    "    particles_df= droplet_approximation.read_particles_data( particles_root,\n",
    "                                                                    target_particle_ids,\n",
    "                                                                    dirs_per_level,\n",
    "                                                                    cold_threshold=cold_threshold,\n",
    "                                                                    filter_be_failures=filter_be_failures,\n",
    "                                                                    evaluations=evaluations )\n",
    "    for graph_index in range(3):\n",
    "        particle_df = particles_df.loc[target_particle_ids[graph_index]]\n",
    "        background_parameters = {\n",
    "            \"Salt Mass (kg)\": particle_df[\"salt masses\"],\n",
    "            \"Air Temperature (K)\": particle_df[\"air temperatures\"],\n",
    "            \"Relative Humidity (%)\": particle_df[\"relative humidities\"],\n",
    "            \"Air Density (g/cm^3)\": particle_df[\"air densities\"]\n",
    "        }\n",
    "        fig, ax_h = droplet_approximation.plot_droplet_size_temperatures_scoring( particle_df, score_report, background_parameters=background_parameters)\n",
    "        #fig, ax_h = droplet_approximation.plot_droplet_size_temperatures_dataframe( particle_df, [reference_tag, comparison_tag], background_parameters=background_parameters)\n",
    "\n",
    "        fig.set_figwidth( 10 )\n",
    "        fig.set_figheight( 10 )\n",
    "        \n",
    "        figure_save_path = \"{:s}cluster_{:d}-trajectory_{:d}-pid={}.png\".format( deviation_figures_dir_path, cluster_index, graph_index, particle_df.name ) \n",
    "        image_substitution_row[\"CLUSTER TRAJECTORY {:d}\".format( graph_index + 1 )] = \"cluster_{:d}-trajectory_{:d}-pid={}.png\".format( cluster_index, graph_index, particle_df.name )\n",
    "        plt.savefig( figure_save_path, bbox_inches=\"tight\" )\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    image_substitution_rows.append( image_substitution_row )\n",
    "    text_substitution_rows.append( text_substitution_row )\n",
    "\n",
    "cluster_image_substitution_table = pd.concat( [pd.DataFrame( [image_substitution_row] ) for image_substitution_row in image_substitution_rows] )\n",
    "cluster_text_substitution_table  = pd.concat( [pd.DataFrame( [text_substitution_row] ) for text_substitution_row in text_substitution_rows] )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680040f3",
   "metadata": {},
   "source": [
    "# Output Substitution Tables\n",
    "We create tables between the image names and their locations. This table enables a script to come through and use the images to auto-populate a google slide for this error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff805b-d8db-426c-a35d-2993381e40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_substitution_table = pd.DataFrame()\n",
    "\n",
    "image_substitution_table[\"Figure Name\"] = figure_filenames.keys()\n",
    "image_substitution_table[\"Figure Filename\"] = figure_filenames.values()\n",
    "\n",
    "image_substitution_table.to_csv( substitutions_dir_path + \"image_substitution_table.csv\", header=False, index=False )\n",
    "\n",
    "text_substitution_table = pd.DataFrame()\n",
    "\n",
    "ppNRMSE = np.array( list( score_report.per_particle_nrmse.values() ) )\n",
    "\n",
    "text_substitutions = {\n",
    "    \"TITLE\": \"Error Analysis of {:s} vs. {:s} in {:s}\".format( reference_tag, comparison_tag, simulation_name ),\n",
    "    \"DATE\": date.today().strftime(\"%d/%m/%Y\"),\n",
    "    \"SHA\": current_SHA,\n",
    "    \"SUBTITLE\": \"{:s} vs. {:s} - {:s}\".format( reference_tag, comparison_tag, simulation_name ),\n",
    "    \"NRMSE\": \"{:.3e}\".format( score_report.net_nrmse ),\n",
    "    \"MEAN PPNRMSE\": \"{:.3e}\".format( np.mean( ppNRMSE ) ),\n",
    "    \"MEDIAN PPNRMSE\": \"{:.3e}\".format( np.median( ppNRMSE ) )\n",
    "}\n",
    "\n",
    "text_substitution_table[\"Figure Name\"]     = text_substitutions.keys()\n",
    "text_substitution_table[\"Figure Filename\"] = text_substitutions.values()\n",
    "\n",
    "text_substitution_table.to_csv( substitutions_dir_path + \"text_substitution_table.csv\", header=False, index=False )\n",
    "\n",
    "cluster_image_substitution_table.to_csv( substitutions_dir_path + \"cluster_image_substitution_table.csv\", index=False )\n",
    "cluster_text_substitution_table.to_csv( substitutions_dir_path + \"cluster_text_substitution_table.csv\", index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
