{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772aafd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Likewise limit pytroch to 1 thread\u001b[39;00m\n\u001b[1;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_num_threads( \u001b[38;5;241m1\u001b[39m )\n\u001b[0;32m---> 18\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_num_interop_threads( \u001b[38;5;241m1\u001b[39m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "# Limit numpy to 1 thread so that\n",
    "# we can parallelize the error analysis\n",
    "# properly\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from droplet_approximation import *\n",
    "\n",
    "# Likewise limit pytroch to 1 thread\n",
    "torch.set_num_threads( 1 )\n",
    "torch.set_num_interop_threads( 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb50436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model corresponds to \"Model Box Uncoupled 400M l1 Residual 14 Epochs\" in the group drive\n",
    "model_load_paths = [\"../models/network_box_uncoupled_400M_l1_residual_epoch_14.pth\"]\n",
    "\n",
    "# These ranges correspond to \"Model Box Uncoupled 400M l1 Residual 14 Epochs\" in the group drive\n",
    "parameter_ranges = {\n",
    "    \"radius\": ( -6.75, -3.00 ),\n",
    "    \"relative_humidity\": ( 0.98, 1.11 )\n",
    "}\n",
    "\n",
    "# Commit for each model\n",
    "commit_SHAs = [\"369bacc0ba5c7367f17ec71707a1df64afd1b6f5\"]\n",
    "\n",
    "# Change this to fit wherever testing data is stored\n",
    "particles_root  = \"../data/particles\"\n",
    "dirs_per_level  = 256\n",
    "\n",
    "# This controls how much of the data to load.\n",
    "# The notebook will load subset_fraction / dirs_per_level\n",
    "# of the overall dataset.\n",
    "subset_fraction = 1\n",
    "\n",
    "# Controls whether to do the graphing/analysis with iterative or direct inference\n",
    "iterative = True\n",
    "\n",
    "# Good CUSUM parameters for iterative, could probably be dialed in more\n",
    "cusum_error_tolerance = np.array( [ 0.02, 0.10 ] )\n",
    "cusum_error_threshold = np.array( [ 0.08, 0.40 ] )\n",
    "\n",
    "# Good CUSUM parameters for non-iterative, could probably be dialed in more\n",
    "#cusum_error_tolerance = np.array( [ 0.005, 0.05 ] )\n",
    "#cusum_error_threshold = np.array( [ 0.02, 0.20 ] )\n",
    "\n",
    "norm = standard_norm\n",
    "\n",
    "# How many processes/batches to run the analysis with\n",
    "# Defaults number_processes to multiprocessing.cpu_count() - 1\n",
    "number_processes = 0\n",
    "number_batches = 1\n",
    "\n",
    "# How many of the worst particles to graph\n",
    "number_graphs = 3\n",
    "\n",
    "# This sets the x-y-z limits for the deviation cluster graph.\n",
    "# Since there are some deviations at very far flung parts of\n",
    "# parameter space, without explicitly setting these ranges,\n",
    "# the deviations are all smooshed together on the graph.\n",
    "deviation_graph_x_range = ( .0,2.0 )\n",
    "deviation_graph_y_range = ( -6.75, -3.50 )\n",
    "deviation_graph_z_range = ( 1.0,1.07 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20253b4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number_processes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     number_processes \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multiprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "if number_processes == 0:\n",
    "    number_processes = multiprocessing.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2122b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make it work with the current model. Remove if using a new model\n",
    "set_parameter_ranges( parameter_ranges )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = len( model_load_paths )\n",
    "\n",
    "model_names = [ path.split( \"/\" )[-1].split( \".\" )[0].replace( \"_\", \" \" ) for path in model_load_paths ]\n",
    "\n",
    "models = [ ResidualNet() for i in range( model_count ) ]\n",
    "\n",
    "for i in range( model_count ):\n",
    "    models[i].load_state_dict( torch.load( model_load_paths[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90631f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 1/256 of the particles\n",
    "ids_index = np.fromfile( \"../data/particles/particles.index\", dtype=np.int32 )\n",
    "filtered_ids = ids_index[ ( ( ids_index // 256 ) % 256 < subset_fraction ) ]\n",
    "\n",
    "df = read_particles_data( particles_root, filtered_ids, dirs_per_level )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_reports = [ ScoringReport( particles_root,\n",
    "                                 filtered_ids, \n",
    "                                 dirs_per_level,\n",
    "                                 models[model_i], \n",
    "                                 model_names[model_i], \n",
    "                                 \"cpu\", \n",
    "                                 cusum_error_tolerance=cusum_error_tolerance, \n",
    "                                 cusum_error_threshold=cusum_error_threshold,\n",
    "                                 iterative=iterative,\n",
    "                                 norm=norm,\n",
    "                                 number_processes=number_processes,\n",
    "                                 number_batches=number_batches,\n",
    "                                 max_clusters=7,\n",
    "                                 parameter_ranges=parameter_ranges )\n",
    "                  for model_i in range ( model_count ) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15938b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_report in score_reports:\n",
    "    # We set precision to 2 because otherwise everything is labeled\n",
    "    # with very long decimals. We can fix this more thoroughly later\n",
    "    with np.printoptions( precision=2 ):\n",
    "        fig,ax = score_report.plot_deviations(label_centers=False)\n",
    "\n",
    "    fig.set_size_inches( ( 8,12 ) )\n",
    "    ax.set_ylim3d( deviation_graph_x_range ) \n",
    "    ax.set_xlim3d( deviation_graph_y_range ) \n",
    "    ax.set_zlim3d( deviation_graph_z_range ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( score_report[0].net_nrsme )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f58a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DF based on first score report\n",
    "df[\"nrmse\"] = score_reports[0].per_particle_nrmse.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "# For each particle, each model will yield 3 figures.\n",
    "# The first will be the figure against BDF\n",
    "# The second will be the figure against BE (with deviations highlighted)\n",
    "# The third will be the figure's CUSUM analysis (calculated within the notebook)\n",
    "\n",
    "colormap = colors.ListedColormap( [\"red\", \"blue\", \"green\", \"orange\", \"black\", \"yellow\"] )\n",
    "\n",
    "for particle_df_index in df.nlargest( n=number_graphs, columns=\"nrmse\" ).index:\n",
    "    particle_df      = df.loc[particle_df_index]\n",
    "    input_parameters = np.stack( particle_df[[\n",
    "        \"input radii\",\n",
    "        \"input temperatures\",\n",
    "        \"salt masses\",\n",
    "        \"air temperatures\",\n",
    "        \"relative humidities\",\n",
    "        \"air densities\",\n",
    "        \"integration times\"\n",
    "    ]].to_numpy(), axis=-1 )\n",
    "\n",
    "    mask             = be_success_mask( input_parameters[:, 0] )\n",
    "    input_parameters = input_parameters[mask]\n",
    "    times            = np.cumsum( input_parameters[:, -1] )\n",
    "\n",
    "    if iterative:\n",
    "        model_outputs = [ do_iterative_inference(\n",
    "                                input_parameters[:, :-1], \n",
    "                                times,\n",
    "                                models[model_index],\n",
    "                                \"cpu\"\n",
    "                            ) for model_index in range( model_count ) ]\n",
    "    else:\n",
    "        model_outputs = [ np.insert( \n",
    "                                    do_inference(\n",
    "                                        input_parameters[:, :-1],\n",
    "                                        input_parameters[:, -1],\n",
    "                                        models[model_index],\n",
    "                                        \"cpu\"\n",
    "                                    )[:-1, :],\n",
    "                                    0, \n",
    "                                    input_parameters[0, :2],\n",
    "                                    axis=0\n",
    "                                ) for model_index in range( model_count ) ]\n",
    "\n",
    "\n",
    "    bdf_output = do_iterative_bdf(\n",
    "        input_parameters[:, :-1],\n",
    "        times\n",
    "    )\n",
    "    be_output  = input_parameters[:, :2]\n",
    "\n",
    "    normed_model_outputs = [ norm( model_output ) for model_output in model_outputs ]\n",
    "    normed_bdf_output    = norm( bdf_output )\n",
    "    normed_be_output     = norm( be_output )\n",
    "\n",
    "    for model_index in range( model_count ): \n",
    "        fig_h_bdf, ax_h_bdf = analyze_model_particle_performance(\n",
    "            times,\n",
    "            bdf_output,\n",
    "            model_outputs[model_index],\n",
    "            norm\n",
    "        )\n",
    "\n",
    "        fig_h_bdf.suptitle( f\"Droplet trajectory overview for particle {model_index} on model {model_names[model_index]} vs. BDF\\n SHA: {commit_SHAs[model_index]}\" ) \n",
    "\n",
    "        fig_h_be, ax_h_be = analyze_model_particle_performance(\n",
    "            times,\n",
    "            input_parameters[:, :2], \n",
    "            model_outputs[model_index],\n",
    "            norm\n",
    "        )\n",
    "\n",
    "        fig_h_be.suptitle( f\"Droplet trajectory overview for particle {model_index} on model {model_names[model_index]} vs. BE\\n SHA: {commit_SHAs[model_index]}\" ) \n",
    "\n",
    "        fig_h_cusum, ax_h_cusum = plt.subplots( 2, 2, figsize=(9,8) )\n",
    "        fig_h_cusum.tight_layout()\n",
    "        fig_h_cusum.suptitle( f\"Droplet trajectory overview part 2 for particle {model_index} on model { model_names[model_index]}\\n SHA: {commit_SHAs[model_index] }\" ) \n",
    "\n",
    "        model_cusum = np.abs( calculate_cusum( ( normed_be_output - normed_model_outputs[model_index] ).T, cusum_error_tolerance ) )\n",
    "\n",
    "        ax_h_cusum[0][0].set_title(\"Radius CUSUM chart\") \n",
    "        ax_h_cusum[0][0].plot( times, model_cusum[0].T, label=[\"positive radius cusum\", \"negative radius cusum\"] )\n",
    "        ax_h_cusum[0][0].set_xlabel( \"time (s)\" )\n",
    "        ax_h_cusum[0][0].axhline( y=cusum_error_threshold[0], color=\"red\",linewidth=1, linestyle=\"--\",label=\"cusum divergence threshold\" )\n",
    "\n",
    "        ax_h_cusum[0][0].set_ylabel(\"CUSUM\")\n",
    "\n",
    "        ax_h_cusum[0][1].plot( times, particle_df[\"relative humidities\"][mask] )\n",
    "        ax_h_cusum[0][1].set_title( \"RH versus time for Particle \" + str( model_index ) )\n",
    "        ax_h_cusum[0][1].set_xlabel( \"time (s)\" )\n",
    "        ax_h_cusum[0][1].set_ylabel( \"Relative Humidity (%)\" ) \n",
    "\n",
    "\n",
    "        ax_h_cusum[1][0].plot( times, particle_df[\"air temperatures\"][mask] - particle_df[\"input temperatures\"][mask] )\n",
    "        ax_h_cusum[1][0].set_title( \"Temperature Difference for Parti/cle \" + str( model_index ) )\n",
    "        ax_h_cusum[1][0].set_xlabel( \"time (s)\" )\n",
    "        ax_h_cusum[1][0].set_ylabel( \"Air Temperature (K)\" ) \n",
    "\n",
    "        ax_h_cusum[1][1].plot( times, particle_df[\"air temperatures\"][mask] )\n",
    "        ax_h_cusum[1][1].set_title( \"Air Temperatures\" + str( model_index ) )\n",
    "        ax_h_cusum[1][1].set_xlabel( \"time (s)\" )\n",
    "        ax_h_cusum[1][1].set_ylabel( \"time step (s)\" ) \n",
    "\n",
    "        for k, deviation_index in enumerate( np.where( score_reports[model_index].deviation_particle_ids == particle_df_index )[0] ):\n",
    "            deviation_parameter = score_reports[model_index].deviation_parameters[deviation_index]\n",
    "            deviation_time      = score_reports[model_index].deviation_times[deviation_index]\n",
    "            deviation_cluster   = score_reports[model_index].deviation_clusters[deviation_index]\n",
    "\n",
    "            line_label = f\"{deviation_parameter.name.lower()} deviation, cluster {deviation_cluster}\", \n",
    "\n",
    "            ax_h_be[0][0].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            ax_h_be[0][1].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            ax_h_be[1][0].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            ax_h_be[1][1].axvline( x=deviation_time,linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "                \n",
    "            ax_h_cusum[0][0].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            ax_h_cusum[0][1].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            ax_h_cusum[1][0].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "            ax_h_cusum[1][1].axvline( x=deviation_time, linewidth=1, linestyle=\"--\", label=line_label, color=colormap( deviation_cluster ) )\n",
    "\n",
    "        ax_h_cusum[0][0].legend()\n",
    "        ax_h_cusum[0][1].legend()\n",
    "        ax_h_cusum[1][0].legend()\n",
    "        ax_h_cusum[1][1].legend()\n",
    "\n",
    "        ax_h_be[0][0].legend()\n",
    "        ax_h_be[0][1].legend()\n",
    "        ax_h_be[1][0].legend()\n",
    "        ax_h_be[1][1].legend()\n",
    "\n",
    "        fig_h_cusum.tight_layout()\n",
    "        fig_h_cusum.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NTLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
